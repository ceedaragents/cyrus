import { createSdkMcpServer, tool } from "@anthropic-ai/claude-agent-sdk";
import fs from "fs-extra";
import OpenAI from "openai";
import type {
	Response,
	ResponseOutputItem,
	Tool,
} from "openai/resources/responses/responses";
import { z } from "zod";

/**
 * Options for creating image generation tools
 */
export interface ImageToolsOptions {
	/**
	 * OpenAI API key
	 */
	apiKey: string;

	/**
	 * Directory to save generated images (default: current working directory)
	 */
	outputDirectory?: string;
}

/**
 * Extended ImageGenerationCall type for documented API fields
 * not yet in the OpenAI SDK type definitions.
 *
 * @see https://platform.openai.com/docs/guides/image-generation#revised-prompt
 */
interface ExtendedImageGenerationCall
	extends ResponseOutputItem.ImageGenerationCall {
	/**
	 * The revised prompt generated by the model for improved image generation.
	 * This is a documented field in the OpenAI API response.
	 */
	revised_prompt?: string;
}

/**
 * Create an SDK MCP server with GPT Image generation tools
 * Uses the Responses API with background mode for async generation
 *
 * @see https://platform.openai.com/docs/guides/image-generation?image-generation-model=gpt-image-1 - GPT Image documentation
 * @see https://platform.openai.com/docs/guides/background - Background mode documentation
 */
export function createImageToolsServer(options: ImageToolsOptions) {
	const { apiKey, outputDirectory = process.cwd() } = options;

	// Initialize OpenAI client
	const client = new OpenAI({
		apiKey,
		timeout: 600 * 1000, // 10 minutes
	});

	// Track format for each job since API doesn't return it
	const jobFormats = new Map<string, string>();

	const generateImageTool = tool(
		"gpt_image_generate",
		"Generate an image using GPT Image (gpt-image-1). This starts an async image generation job and returns a job ID. Use gpt_image_get to wait for completion and download the image.",
		{
			prompt: z
				.string()
				.describe(
					"Text description of the image you want to generate. Be as detailed as possible for best results.",
				),
			size: z
				.enum(["1024x1024", "1536x1024", "1024x1536", "auto"])
				.optional()
				.default("auto")
				.describe(
					"Image size: 1024x1024 (square), 1536x1024 (landscape), 1024x1536 (portrait), or auto (model decides)",
				),
			quality: z
				.enum(["low", "medium", "high", "auto"])
				.optional()
				.default("auto")
				.describe(
					"Image quality: low (fastest), medium, high (best quality), or auto (model decides). Higher quality uses more tokens and takes longer.",
				),
			background: z
				.enum(["transparent", "opaque", "auto"])
				.optional()
				.default("auto")
				.describe(
					"Background type: transparent (PNG/WebP only), opaque, or auto (model decides)",
				),
			output_format: z
				.enum(["png", "jpeg", "webp"])
				.optional()
				.default("png")
				.describe(
					"Output format: png (default, supports transparency), jpeg (faster), or webp (good compression)",
				),
			output_compression: z
				.number()
				.min(0)
				.max(100)
				.optional()
				.describe(
					"Compression level for jpeg/webp (0-100%). Higher = less compression, larger file. Only applicable for jpeg and webp formats.",
				),
		},
		async ({
			prompt,
			size,
			quality,
			background,
			output_format,
			output_compression,
		}) => {
			try {
				console.log(
					`[ImageTools] Starting image generation: ${prompt.substring(0, 50)}... (${size}, ${quality}, ${output_format})`,
				);

				// Validate background transparency is only for PNG/WebP
				if (background === "transparent" && output_format === "jpeg") {
					return {
						content: [
							{
								type: "text" as const,
								text: JSON.stringify({
									success: false,
									error:
										"Transparent backgrounds are only supported with png or webp formats, not jpeg",
								}),
							},
						],
					};
				}

				// Build tool configuration
				const toolConfig: Tool.ImageGeneration = {
					type: "image_generation",
				};

				// Add optional parameters (only if not auto)
				if (size !== "auto") toolConfig.size = size;
				if (quality !== "auto") toolConfig.quality = quality;
				if (background !== "auto") toolConfig.background = background;
				if (output_format) toolConfig.output_format = output_format;
				if (output_compression !== undefined)
					toolConfig.output_compression = output_compression;

				// Use Responses API with background mode for async processing
				const response = await client.responses.create({
					model: "gpt-5", // Wrapper model that can call image_generation tool
					background: true, // Enable async mode
					store: true, // Store result for retrieval
					tools: [toolConfig],
					input: [
						{
							role: "user",
							content: prompt,
						},
					],
				});

				console.log(
					`[ImageTools] Image generation job started: ${response.id}`,
				);

				// Store the format for this job so we know the extension when downloading
				jobFormats.set(response.id, output_format || "png");

				return {
					content: [
						{
							type: "text" as const,
							text: JSON.stringify({
								success: true,
								jobId: response.id,
								status: response.status,
								message:
									"Image generation job started. Use gpt_image_get to wait for completion and download the image.",
							}),
						},
					],
				};
			} catch (error) {
				console.error("[ImageTools] Error starting image generation:", error);
				return {
					content: [
						{
							type: "text" as const,
							text: JSON.stringify({
								success: false,
								error: error instanceof Error ? error.message : String(error),
							}),
						},
					],
				};
			}
		},
	);

	const getImageTool = tool(
		"gpt_image_get",
		"Check if GPT Image generation is complete and download the image if ready. If not ready, returns status. Call this tool again later if the image is not ready yet.",
		{
			jobId: z.string().describe("The job ID from gpt_image_generate"),
			filename: z
				.string()
				.optional()
				.describe(
					"Custom filename for the image (default: generated-{jobId}.png)",
				),
		},
		async ({ jobId, filename }) => {
			try {
				console.log(`[ImageTools] Checking image generation job: ${jobId}`);

				// Check job status once
				const response: Response = await client.responses.retrieve(jobId);

				console.log(`[ImageTools] Job ${jobId} status: ${response.status}`);

				// If not completed, return status
				if (response.status !== "completed") {
					if (response.status === "failed") {
						return {
							content: [
								{
									type: "text" as const,
									text: JSON.stringify({
										success: false,
										error: "Image generation failed",
										jobId,
										status: response.status,
									}),
								},
							],
						};
					}

					// Still in progress
					return {
						content: [
							{
								type: "text" as const,
								text: JSON.stringify({
									success: false,
									ready: false,
									jobId,
									status: response.status,
									message: `Image is not ready yet. Current status: ${response.status}. Try calling gpt_image_get again in a few moments.`,
								}),
							},
						],
					};
				}

				// Image is ready - download it
				console.log(
					`[ImageTools] Image generation completed for job: ${jobId}`,
				);

				// Extract image data from output
				const imageGenerationCall = response.output?.find(
					(
						item: ResponseOutputItem,
					): item is ResponseOutputItem.ImageGenerationCall =>
						item.type === "image_generation_call",
				);

				if (!imageGenerationCall) {
					return {
						content: [
							{
								type: "text" as const,
								text: JSON.stringify({
									success: false,
									error: "No image generation data found in response",
								}),
							},
						],
					};
				}

				const base64Data = imageGenerationCall.result;
				const extendedCall = imageGenerationCall as ExtendedImageGenerationCall;
				const revisedPrompt = extendedCall.revised_prompt;

				if (!base64Data) {
					return {
						content: [
							{
								type: "text" as const,
								text: JSON.stringify({
									success: false,
									error: "No image data found in response",
								}),
							},
						],
					};
				}

				// Convert base64 to buffer
				const buffer = Buffer.from(base64Data, "base64");

				// Ensure output directory exists
				await fs.ensureDir(outputDirectory);

				// Get the format we requested when creating the job (defaults to png)
				const format = jobFormats.get(jobId) || "png";
				const ext = format.toLowerCase();

				// Determine final filename
				const timestamp = Date.now();
				const finalFilename =
					filename || `generated-${jobId.substring(0, 8)}-${timestamp}.${ext}`;
				const filePath = `${outputDirectory}/${finalFilename}`;

				// Write to disk
				await fs.writeFile(filePath, buffer);

				// Clean up stored format
				jobFormats.delete(jobId);

				console.log(`[ImageTools] Image saved to: ${filePath}`);
				if (revisedPrompt) {
					console.log(`[ImageTools] Revised prompt: ${revisedPrompt}`);
				}

				return {
					content: [
						{
							type: "text" as const,
							text: JSON.stringify({
								success: true,
								filePath,
								filename: finalFilename,
								size: buffer.length,
								jobId,
								model: "gpt-image-1",
								revisedPrompt: revisedPrompt || undefined,
								message: `Image downloaded and saved to ${filePath}`,
							}),
						},
					],
				};
			} catch (error) {
				console.error(
					`[ImageTools] Error downloading image for job ${jobId}:`,
					error,
				);
				return {
					content: [
						{
							type: "text" as const,
							text: JSON.stringify({
								success: false,
								error: error instanceof Error ? error.message : String(error),
							}),
						},
					],
				};
			}
		},
	);

	return createSdkMcpServer({
		name: "image-tools",
		version: "1.0.0",
		tools: [generateImageTool, getImageTool],
	});
}
